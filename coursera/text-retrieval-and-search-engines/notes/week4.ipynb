{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 Overview\n",
    "\n",
    "During this week's lessons, you will learn probabilistic retrieval models and statistical language models, particularly the detail of the query likelihood retrieval function with two specific smoothing methods, and how the query likelihood retrieval function is connected with the retrieval heuristics used in the vector space model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Phrases and Concepts\n",
    "\n",
    "* p(R=1|q,d) ; query likelihood, p(q|d)\n",
    "* Statistical and unigram language models\n",
    "* Maximum likelihood estimate\n",
    "* Background, collection, and document language models\n",
    "* Smoothing of unigram language models\n",
    "* Relation between query likelihood and TF-IDF weighting\n",
    "* Linear interpolation (i.e., Jelinek-Mercer) smoothing\n",
    "* Dirichlet Prior smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals and Objectives\n",
    "\n",
    "* Explain how to interpret p(R=1|q,d) and estimate it based on a large set of collected relevance judgments (or clickthrough information) about query q and document d.\n",
    "* Explain how to interpret the conditional probability p(q|d) used for scoring documents in the query likelihood retrieval function.\n",
    "* Explain what a statistical language model and a unigram language model are.\n",
    "* Explain how to compute the maximum likelihood estimate of a unigram language model.\n",
    "* Explain how to use unigram language models to discover semantically related words.\n",
    "* Compute p(q|d) based on a given document language model p(w|d).\n",
    "* Explain what smoothing does.\n",
    "* Show that query likelihood retrieval function implements TF-IDF weighting if we smooth the document language model p(w|d) using the collection language model p(w|C) as a reference language model.\n",
    "* Compute the estimate of p(w|d) using Jelinek-Mercer (JM) smoothing and Dirichlet Prior smoothing, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guiding Questions\n",
    "\n",
    "A very good note with practical examples can be found at [elastic search blog](https://www.elastic.co/blog/language-models-in-elasticsearch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given a table of relevance judgments in the form of three columns (query, document, and binary relevance judgments), how can we estimate p(R=1|q,d)?\n",
    "\n",
    "Let:\n",
    "\n",
    "- $Q$ is set of query, such that $Q = \\{q_1, ..., q_n\\}$\n",
    "- $D$ is set of document, such that $D = \\{d_1, ..., d_n\\}$\n",
    "- $R$ is a binary random variable denoting relevance, such that $R \\in \\{0,1\\}$\n",
    "\n",
    "We have:\n",
    "\n",
    "- $U$ is set of users, such that $U = \\{u_1, ..., u_n\\}$\n",
    "- Value of $R$ for each pair $(q,d)$ is judged by user\n",
    "- $f(q,d)$ is our ranking function\n",
    "\n",
    "Then:\n",
    "\n",
    "- $f(q,d) = P(R=1|q,d)$\n",
    "- $P(R=1|q,d)$ tells us that document $d$ is relevant to query $q$ such that:\n",
    "\n",
    "$$P(R=1|q,d) = \\frac{count(q,d,R=1)}{count(q,d)} = \\frac{c(i, R=1)}{N}$$\n",
    "\n",
    "With constrain:\n",
    "\n",
    "- $P(R=1|q,d) + P(R=0|q,d) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How should we interpret the query likelihood conditional probability p(q|d)?\n",
    "\n",
    "Problem:\n",
    "\n",
    "- In the such case, we can not afford complete labeled data for each $(q,d,R)$\n",
    "- We need to find a way to match new query $q$ with relevant documents $\\{d_i, ..., d_n\\}$.\n",
    "\n",
    "Assume:\n",
    "\n",
    "- We already have data about user preferences based on click histories on particular documents. In other word, we know what kind of documents liked by user. \n",
    "\n",
    "Then:\n",
    "\n",
    "- **Query likehood** $P(q|d)$ is approximation to predict query $q$ based user interest on partcular documents $\\{d_i, ..., d_n\\}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a statistical language model? What is a unigram language model? How many parameters are there in a unigram language model?\n",
    "\n",
    "- **Statistical language model** is probability distribution over word sequence. It used word sequence strictly, its means $\\{w_1+w_2+w_3\\} \\neq \\{w_3+w_1+w_2\\}$. Also called as **generative model** because can generate possible word sequence using *finite automaton alorithm*, then each generated word sequences can be used for *auto completion* task. Further, generated strings can be used to help *speech recognition* predict next possible word based on the probability. Since intuitively, the best next word is a word with high probabilty in the context of previous words. The probability of word sequence is:\n",
    "\n",
    "$$P(q|d) = P(\\{w_1, ..., w_n\\}|d) = \\frac{count(w_1+...+w_n)}{|d|} = \\frac{c(q)}{N}$$\n",
    "\n",
    "- **Unigram language model** is product of each word probability.\n",
    "\n",
    "$$\\prod P(w_i|V) = \\prod \\frac{count(w_i)}{|V|} = \\prod \\frac{c(w_i)}{N}$$\n",
    "\n",
    "where $V$ is vocaboulary and $N$ is vocaboulary size. Since unigram language model depend ont independent calculation, then it has $N$ parameters of $P(w_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we compute the maximum likelihood estimate of the unigram language model (based on a text sample)?\n",
    "\n",
    "Let:\n",
    "\n",
    "- $d$ is document contains text sample\n",
    "\n",
    "Then:\n",
    "\n",
    "- Maximum likehood (ML) estimator is:\n",
    "$$P(w|\\theta) = P(w|d) = \\frac{c(w,d)}{|d|}$$\n",
    "\n",
    "- For sequence of $w$ in $q$, ML estimator is:\n",
    "\n",
    "$$\\eqalign{\n",
    "    P(q|\\theta) &= \\prod P(w_i|d)\\\\\n",
    "                &= \\prod \\frac{c(w,d)}{|d|}\\\\\n",
    "                \\text{Transform to logarithmic to avoid underflow:}\\\\\n",
    "    P(q|\\theta) &= \\sum c(w,q)\\ log\\ P(w|d) \n",
    "}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a background language model? What is a collection language model? What is a document language model?\n",
    "\n",
    "- **Background language model**: A model $M_B$ which try to find general probability of word $P(w|M_B)$ based on text of general specific language. For example, english vocaboulary, dictionary, WordNet, etc.\n",
    "- **Collection language model**: A model $M_C$ which find probability of word $P(w|M_C)$ based on group of documents in the collection.\n",
    "- **Document language model**: A model $M_D$ which find probability of word $P(w|M_D)$ based only on specific document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we need to smooth a document language model in the query likelihood retrieval model? What would happen if we donâ€™t do smoothing?\n",
    "\n",
    "- We need to smoothing the document language model when there are some unknown words in the query. We make assumtion that the probability of unknown words would be proportional to its probability given by reference language model. So that:\n",
    "    - Assign $P(w|M_C)$ for word not found in the document (unkown word).\n",
    "    - Discounted $P(w|M_D)/P(w|M_C)$ for word fount in the document. \n",
    "- If we do not smoothing, then the probability of unkown words became zero and probability of word in specific document may too high. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When we smooth a document language model using a collection language model as a reference language model, what is the probability assigned to an unseen word in a document?\n",
    "\n",
    "In the case of retrieval, collection language model is natural choice as reference language model. We use collection as reference when there are any unkown words that did not found in the set of known documents. Thus, we calculate the probability of any unkown words proportional to the collection language model. The calculation of word probability will be:\n",
    "\n",
    "$$P(w|d) = \\begin{cases}\n",
    "P_{seen}(w|d), \\text{ for known words}\\\\\\\\\n",
    "\\alpha_d P(w|C), \\text{ for unkown words}\n",
    "\\end{cases}$$\n",
    "\n",
    "where $\\alpha_d$ is coefficient to control probabiliy mass of unkown words and $C$ is collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we prove that the query likelihood retrieval function implements TF-IDF weighting if we use a collection language model smoothing?\n",
    "\n",
    "Let use logarithmic maximum likehood as ranking function, then:\n",
    "$$\\eqalign{\n",
    "    log P(w|d) &= \\sum\\limits_{w \\in V} c(w,q)\\ log P(w|d)\\\\\n",
    "               &= \\text{query matched in } d + \\text{query not matched in } d\\\\\n",
    "               &= \\sum\\limits_{w \\in V, c(w,d)>0} c(w,q)\\ log P_{seen}(w|d) + \\sum\\limits_{w \\in V, c(w,d)=0} c(w,q)\\ log\\alpha_d \\ P(w|C)\\\\\n",
    "               &= \\sum\\limits_{w \\in V, c(w,d)>0} c(w,q)\\ log P_{seen}(w|d) + \\big(P \\text{ of all query words} - P \\text{ of query words matched in } d \\big)\\\\\n",
    "               &= \\sum\\limits_{w \\in V, c(w,d)>0} c(w,q)\\ log P_{seen}(w|d) + \\big(\\sum\\limits_{w \\in V} c(w,q)\\ log \\alpha_d \\ P(w|C) - \\sum\\limits_{w \\in V, c(w,d)>0} c(w,q)\\ log \\alpha_d \\ P(w|C) \\big)\\\\\n",
    "               &= \\sum\\limits_{w \\in V, c(w,d)>0} c(w,q)\\ log \\frac{P_{seen}(w|d)}{\\alpha_d P(w|C)} + |q| log \\alpha_d + \\sum\\limits_{w \\in V} c(w,q)\\ log \\ P(w|C)\n",
    "}$$\n",
    "\n",
    "The decomposition can be seen in an image below:\n",
    "\n",
    "![query likehood heuristics](images/query-likehood-heuristics.png)\n",
    "\n",
    "so then, **our ranking function became similar to vector space model with different that the TF-IDF weighting and document length normalization derived from probability with penalization parameter $\\alpha_d$ which has high value for short documents and low value for long documents**. We can ignore the last sum calculation since sum of word probability of collection always constant. But, we keep second calculation altough it always constant. We need document length normalization to ensuring rank accuracy. For example, if we have many short document and 4-bit accuracy, then it may be case that two rank values $0.00013 = 0.00014$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does linear interpolation (Jelinek-Mercer) smoothing work? What is the formula?\n",
    "\n",
    "**Jelinek-Mercer smoothing** is linear interpolation between the maximum likehood estimate and the collection language model controlled by fixed smoothing parameter $\\lambda \\in [0,1]$:\n",
    "- High $\\lambda$ means increasing the important of the collection model and may diminishing the important of the document model. Higher $\\lambda$ may useful for longer query.\n",
    "- Low $\\lambda$ means give priority for the document model. Lower $\\lambda$ may useful for shorter query.\n",
    "\n",
    "Jelinek-Mercer smoothing formula is:\n",
    "\n",
    "$$P_{seen}(w|d) = (1-\\lambda)\\ P_{MLE}(w|d) + \\lambda \\ P(w|C)$$\n",
    "\n",
    "where $P_{MLE}$ is Maximum Likehood Estimate which is zero if a word not appeared in the document.\n",
    "\n",
    "For whole query, the formula become:\n",
    "$$P_{seen}(w|d) = \\prod \\big[(1-\\lambda)\\ P_{MLE}(w|d) + \\lambda \\ P(w|C)\\big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does Dirichlet prior smoothing work? What is the formula?\n",
    "\n",
    "**Dirichlet prior smoothing** or *Bayesian smoothing* is linear interpolation between the maximum likehood estimate and the collection language model controlled by dynamic smoothing parameter $\\mu \\in [0,+\\infty)$, also called as dynamic coefficient interpolation:\n",
    "\n",
    "- High $\\mu$ for short document.\n",
    "- Low $\\mu$ for long document.\n",
    "- $\\mu$ satisfy:\n",
    "$$P(d,\\mu) = \\frac{|d|}{|d|+\\mu}+\\frac{\\mu}{|d|+\\mu}=1$$\n",
    "\n",
    "Dirichlet prior smoothing formula is:\n",
    "\n",
    "$$\\eqalign{\n",
    "    P(w|d) &= \\frac{c(w,d)+\\mu * P(w|C)}{|d|+\\mu}\\\\\n",
    "           &= \\frac{|d|}{|d|+\\mu} \\frac{c(w,d)}{|d|} + \\frac{\\mu}{|d|+\\mu}P(w|C)\n",
    "}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the similarities and differences between Jelinek-Mercer smoothing and Dirichlet prior smoothing?\n",
    "\n",
    "Both smoothing formula similar to vector space model, but JM has fixed dependent parameter which lead to ignore document length normalization contrast with Dir has dynamic coefficient:\n",
    "\n",
    ">Given ranking functing consisted of TF-IDF weighting and length normalization:\n",
    "\n",
    ">$$log P(w|d) = \\sum\\limits_{w \\in V, c(w,d)>0} c(w,q)\\ log \\frac{P_{seen}(w|d)}{\\alpha_d P(w|C)} + |q| log \\alpha_d$$\n",
    "\n",
    ">Jelinek-Mercer smoothing is:\n",
    "    \n",
    ">$$P_{seen}(w|d) = (1-\\lambda)\\ P_{MLE}(w|d) + \\lambda \\ P(w|C)$$\n",
    "\n",
    ">If $\\alpha_d = \\lambda$, then:\n",
    "\n",
    ">$$\\eqalign{\n",
    "    \\frac{P_{seen}(w|d)}{\\alpha_d*P(w|C)} &= \\frac{(1-\\lambda)\\ P_{MLE}(w|d) + \\lambda \\ P(w|C)}{\\lambda * P(w|C)}\\\\\n",
    "    &= 1 + \\frac{1-\\lambda}{\\lambda} * \\frac{c(w,d)}{|d|*P(w|C)}\n",
    "}$$\n",
    "\n",
    ">Ignore the $|q|log \\alpha_d$ since $\\alpha_d = \\lambda$ not depend on the current document being scored.\n",
    "\n",
    ">Finally, scoring function is:\n",
    "\n",
    "$$score_{JM}(q,d) = \\sum\\limits_{w \\in q,d} c(w,d) \\ log\\big(1+\\frac{1-\\alpha}{\\alpha}*\\frac{c(w,d)}{|d|*P(w|C)}\\big)$$\n",
    "\n",
    "---\n",
    "\n",
    ">Dirichlet prior smoothing is:\n",
    "\n",
    ">$$\\eqalign{\n",
    "    P_{seen}(w|d) &= \\frac{c(w,d)+\\mu * P(w|C)}{|d|+\\mu}\\\\\n",
    "                  &= \\frac{|d|}{|d|+\\mu} \\frac{c(w,d)}{|d|} + \\frac{\\mu}{|d|+\\mu}P(w|C)\n",
    "}$$\n",
    "\n",
    ">If $\\alpha_d = \\frac{\\mu}{|d|+\\mu}$, then:\n",
    "\n",
    ">$$\\eqalign{\n",
    "    \\frac{P_{seen}(w|d)}{\\alpha_d*P(w|C)} &= \\frac{\\frac{c(w,d)+\\mu * P(w|C)}{|d|+\\mu}}{\\frac{\\mu}{|d|+\\mu}P(w|C)}\\\\\n",
    "    &= 1 + \\frac{c(w,d)}{\\mu * P(w|C)}\n",
    "}$$\n",
    "\n",
    ">Finally, scoring function is:\n",
    "\n",
    ">$$score_{Dir}(q,d) = \\sum\\limits_{w \\in q,d} c(w,q)\\ log \\big(1+\\frac{c(w,d)}{\\mu*P(w|C)} + |q| log \\frac{\\mu}{\\mu + |d|}\\big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Readings and Resources\n",
    "\n",
    "* C. Zhai and S. Massung. Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining, ACM Book Series, Morgan & Claypool Publishers, 2016. Chapter 6 - Section 6.4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 Overview\n",
    "\n",
    "During this week's lessons, you will learn how machine learning can be used to combine multiple scoring factors to optimize ranking of documents in web search (i.e., learning to rank), and learn techniques used in recommender systems (also called filtering systems), including content-based recommendation/filtering and collaborative filtering. You will also have a chance to review the entire course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Phrases and Concepts\n",
    "\n",
    "* Learning to rank, features, and logistic regression\n",
    "* Content-based filtering\n",
    "* Collaborative filtering\n",
    "* Beta-gamma threshold learning\n",
    "* Linear utility\n",
    "* User profile\n",
    "* Exploration-exploitation tradeoff\n",
    "* Memory-based collaborative filtering\n",
    "* Cold start "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals and Objectives\n",
    "\n",
    "After you actively engage in the learning experiences in this module, you should be able to:\n",
    "\n",
    "* Explain the basic idea of using machine learning to combine multiple features for ranking documents (i.e., learning to rank).\n",
    "* Explain how we can extend a retrieval system to perform content-based information filtering (recommendation).\n",
    "* Explain how we can use a linear utility function to evaluate an information filtering system.\n",
    "* Explain the basic idea of collaborative filtering.\n",
    "* Explain how the memory-based collaborative filtering algorithm works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guiding Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What’s the basic idea of learning to rank?\n",
    "\n",
    "Use machine learning to combine many different features into a single learning function to optimize search results.\n",
    "\n",
    "Let:\n",
    "\n",
    "- $(Q, D)$ is vector of query-document pair.\n",
    "- $X_i(Q, D)$ is vector of feature $i$.\n",
    "- $X_i(Q, D)$ can be BM25 score, p(Q|D), PageRank, or custom scoring function such as URL pattern detection.\n",
    "\n",
    "Hypothesize:\n",
    "\n",
    "- The relevance defined by system of $X_i$, such that:\n",
    "\n",
    "$$p(R=1|Q,D) = s(X_0(Q, D), ..., X_n(Q,D), \\lambda)$$\n",
    "\n",
    "- $s$ is fitting function.\n",
    "- $\\lambda$ is parameters that control weight of each feature in fitting function $s$.\n",
    "\n",
    "Then:\n",
    "\n",
    "- Find best value of $\\lambda$ that maximize fitting function $s$ by using statistical analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can logistic regression be used to combine multiple features for improving ranking accuracy of a search engine?\n",
    "\n",
    "Let:\n",
    "\n",
    "- $s()$ is logistic regression that learn from labeled training data.\n",
    "- Training data consists of $(q_i, d_i, R)$ tuples.\n",
    "- $q_i$ is a query consists terms $\\{t_1, ..., t_q\\}$\n",
    "- $R$ is user judgment.\n",
    "\n",
    "Hypothesize:\n",
    "\n",
    "- The *logistic inference model* says that we can use *random sample* of *query-document-term* triples for which binary relevance judgement have been made, and compute the logarithm of the odds of relevance for term $t_k$ which s present in both document $d_j$ and query $q_i$ by the formula:\n",
    "\n",
    "$$log P(R|q_i, d_j, t_k) = \\beta_0 + \\beta_1 x_1 + ... + \\beta_n x_n$$\n",
    "\n",
    "Find:\n",
    "\n",
    "- Parameters $\\beta$ that fit in $log P(R|q_i, d_j, t_k)$.\n",
    "- Probability of relevance for query $q_i = \\{t_1, ..., r_q\\}$ is the sum of log odds for all terms:\n",
    "$$log P(R|q_i, d_j) = \\sum\\limits_{k=1}^q \\big[ log P(R|q_i, d_j, t_k) - log P(R) \\big]$$\n",
    "- $P(R)$ known as *prior odds of relevance* is the probability that a document chosen at random from the collection will be relevant to query $q_i$. For example:\n",
    "    - $N_j$ is number of assigned judgement.\n",
    "    - $N_{q,d}$ is number of query-document pairs in the collection.\n",
    "    - Then:\n",
    "    $$P(R) = prior = \\frac{N_j}{N_{q,d}}$$\n",
    "    - The log version is:\n",
    "    $$log P(R) = log \\ prior = log \\frac{P(R)}{1 - P(R)} = log \\frac{prior}{1 - prior}$$\n",
    "\n",
    "Finally:\n",
    "\n",
    "- Probability of relevance of a document to a query is:\n",
    "$$P(R|q_i, d_j) = \\frac{1}{1+e^{-log P(R|q_i, d_j)}}$$\n",
    "\n",
    "Please read [this paper](http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=B6ADD5FAE7AAB2AFF0030B55AB6AC7DA?doi=10.1.1.64.4681&rep=rep1&type=pdf) for further explanation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:\n",
    "\n",
    "Let:\n",
    "\n",
    "- $X_1$ is BM25 score of the document for the query.\n",
    "- $X_2$ is PageRank score of the document.\n",
    "- $X_3$ is BM25 score on the anchor text of the document.\n",
    "\n",
    "We know that:\n",
    "\n",
    "- Model of relevant and model of non relevant:\n",
    "\n",
    "\n",
    " model | $X_1(Q, D)$ | $X_2(Q, D)$ | $X_3(Q, D)$ |\n",
    "-------|-------------|-------------|-------------|\n",
    "$d_1(R=1)$ | 0.7 | 0.11 | 0.65 |\n",
    "$d_2(R=0)$ | 0.3 | 0.05 | 0.4  |\n",
    "\n",
    "\n",
    "Find:\n",
    "\n",
    "- $\\beta$ parameters that maximize:\n",
    "\n",
    "$$P(\\{q, d_1, R=1\\}, \\{q, d_2, R=0\\},) = \\frac{1}{1 + exp(-\\beta_0 - 0.7 \\beta_1 - 0.11 \\beta_2 - 0.65 \\beta_3)} * \\Big(1 - \\frac{1}{1 + exp(-\\beta_0 - 0.3 \\beta_1 - 0.05 \\beta_2 - 0.4 \\beta_3)} \\Big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is content-based information filtering?\n",
    "\n",
    "Let:\n",
    "\n",
    "- $u$ is user.\n",
    "- $x$ is item.\n",
    "\n",
    "Find:\n",
    "\n",
    "- Will user $u$ like item $x$?\n",
    "\n",
    "Then:\n",
    "\n",
    "- Learn what $u$ likes.\n",
    "- Recommend $x$ to $u$ based on user characteristics of liked items.\n",
    "\n",
    "![content-based-information-filtering](images/content-based-information-filtering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we use a linear utility function to evaluate a filtering system? <br> How should we set the coefficients in such a linear utility function? \n",
    "\n",
    "Problem 1:\n",
    "\n",
    "- Can not waiting for document pooling to make decision what user characteristics, thus can not used MAP (Mean Average Pricision) or NDCG (Normalized Discounted Cumulative Gain).\n",
    "\n",
    "Solution:\n",
    "\n",
    "- Should be able to make a decision in real time.\n",
    "\n",
    "Find:\n",
    "\n",
    "- Threshold $\\theta$ to define abosolute value of relevance in user perspective.\n",
    "\n",
    "Then:\n",
    "\n",
    "- $R$ is set of relevant that have value above threshold $\\theta$.\n",
    "- $R'$ is set of non relevant that have value below or equal threshold $\\theta$.\n",
    "\n",
    "Finally:\n",
    "\n",
    "- A linear utility function can be used to measure user charateristics is:\n",
    "$$U = \\alpha_0 * |R| - \\alpha_1 * |R'|$$\n",
    "that quantify how user give reward to relevant document as subset of whole delivered documents.\n",
    "\n",
    "---\n",
    "\n",
    "Problem 2:\n",
    "\n",
    "- How to set utility parameters $\\alpha$?\n",
    "\n",
    "Solution:\n",
    "\n",
    "- Find parameters $\\alpha$ that maximize the utility function $U$.\n",
    "- List of modules can be deployed to optimize parameters $\\alpha$.\n",
    "\n",
    "Three basic modules are:\n",
    "\n",
    "- **Initialization module**: Set initial model of user characteristics based on very limited information.\n",
    "- **Decision module**: Decide which document should be delivered to user over time to know user preferences.\n",
    "- **Learning module**: Based on output of decision module, dynamically analyze anomaly of user behavior while enhance decision module performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we extend a retrieval system to perform content-based information filtering?\n",
    "\n",
    "Let:\n",
    "\n",
    "- Retrieval system implements general **vector space model**.\n",
    "- $\\vec{D}$ is vector of documents.\n",
    "- $\\vec{Q}_+$ is extended query contains user profile (preferences, behavior, etc).\n",
    "\n",
    "Then:\n",
    "\n",
    "- Implement **scoring module** to quantify $\\vec{D}$ based on $\\vec{Q}_+$.\n",
    "- Implement **Thresholding module** to decide any document to be delivered to user.\n",
    "\n",
    "Finally:\n",
    "\n",
    "- Update threshold value $\\theta$ based on feedback from user.\n",
    "- Update $\\vec{Q}_+$ by learning from user feedback.\n",
    "\n",
    "![content-based-recommendation-feedback](images/content-based-recommendation-feedback.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the exploration-exploitation tradeoff?\n",
    "\n",
    "Let:\n",
    "\n",
    "- **Exploration** is explore unlabelled documents to be delivered to user to get feedback as much as possible to gt know user preferences.\n",
    "- **Exploitation** is exploit user feedback based on known user preferences at current time.\n",
    "\n",
    "Constrains:\n",
    "\n",
    "- If system do too deep exploration, then many unrelevant documents may delvired to users, thus decrease user satisfication.\n",
    "- If system do too much exploitation, then decrease system capability to learn new user preferences.\n",
    "\n",
    "Then:\n",
    "\n",
    "- Use **beta-gamma threshold learning** to solve exploration-exploitation tradeoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the beta-gamma threshold learning algorithm work? \n",
    "\n",
    "The basic idea of beta-gamma threshold learning is:\n",
    "\n",
    "1. Given a ranked list of all documents in the the training database sorted by their scores, their relevance, and utility score $U$.\n",
    "![beta-gamma-threshold](images/beta-gamma-threshold.png)\n",
    "2. Find $\\theta_{optimal}$ is maximum threshold which is used to start exploration, thus $\\theta_{optimal}$ also indicate maximum utility.\n",
    "3. Decide $\\theta_{zero}$ which is minimum threshold which is used to stop exploration, thus $\\theta_{zero}$ also indicate minimum utility.\n",
    "4. **Cutoff position** is any documents that have utility between $\\theta_{optimal}$ and $\\theta_{zero}$. The exploration should executed between cutoff position, such that:\n",
    "$$\\theta = \\alpha * \\theta_{zero} + (1 - \\alpha) * \\theta_{optimal}$$\n",
    "5. $\\alpha$ is parameter which control deviation from optimal utility $\\theta_{optimal}$. $\\alpha$ defined as:\n",
    "$$\\alpha = \\beta + (1 - \\beta) * e^{-N*\\gamma}$$\n",
    "6. $\\beta$ parameter controls the deviation from $\\theta_{optimal}$, which can be based on previously observer documents (i.e., training data).\n",
    "7. $\\gamma$ parameter controls the influence of the number of examples in the training data set.\n",
    "8. $N$ is number of data set.\n",
    "9. $e^{-N * \\gamma}$ tells us that:\n",
    "    - Less exploration if $N$ became greater.\n",
    "    - More exploration if $N$ very small.\n",
    "\n",
    "Please read [this paper](http://www.cs.cmu.edu/~czhai/paper/TREC7-filtering.pdf) for further explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the basic idea of collaborative filtering?\n",
    "\n",
    "Let:\n",
    "\n",
    "- $u_i$ is user.\n",
    "- $U_a$ is set of similar users.\n",
    "- $x_i$ is item to be recommended to $u_i$.\n",
    "- $X_a$ is set of items liked by $U_a$.\n",
    "\n",
    "Problem:\n",
    "\n",
    "- Will user $u_i$ like item $x_i$?\n",
    "\n",
    "Assume:\n",
    "\n",
    "- Users with the same interest will have similar preferences, and vice versa.\n",
    "\n",
    "Then:\n",
    "\n",
    "- Find $U_a$ that have similar characteristics to $u_i$.\n",
    "- Predict $u_i$ preferences based on common preferences of $U_a$.\n",
    "\n",
    "Finally:\n",
    "\n",
    "- Recommend $x_i$ to $u_i$ if only if $x_i$ similar or belong to $X_a$.\n",
    "\n",
    "---\n",
    "\n",
    "Below is sparse matrix representation used for collaborative filtering where $o$ is object of document and function $f(., .)$ map a user and object to a rating.\n",
    "\n",
    "![collaborative-filtering](images/collaborative-filtering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the memory-based collaborative filtering algorithm work?\n",
    "\n",
    "Let:\n",
    "\n",
    "- $u_i$ is a user with known preferences.\n",
    "- $u_a$ is a user with unkown preferences. \n",
    "- $X_{ij}$ is rating given by user $u_i$ to object $o_j$.\n",
    "- $n_i$ is average rating of all objects by user $u_i$.\n",
    "- $n_a$ is average rating of all objects by user $u_a$.\n",
    "- Normalized ratings for each user $u_i$:\n",
    "$$V_{ij} = X_{ij} - n_i$$\n",
    "\n",
    "Predict:\n",
    "\n",
    "- Rating $\\hat{X}_{aj}$ of object $o_j$ given by user $u_a$?\n",
    "\n",
    "Assume:\n",
    "\n",
    "- If predicted rating of $o_j$ is high, then object $o_j$ may be a good candidate to be recommended to user $u_a$.\n",
    "\n",
    "Then:\n",
    "\n",
    "- Predicted normalized rating of object $o_j$ to user $u_a$ is:\n",
    "\n",
    "$$\\hat{V}_{aj} = k * \\sum\\limits_{i=1}^m w(u_a, u_i) * V_{ij}$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $k$ is normalizer that ensures $\\hat{V}_{aj} \\in [0, 1]$:\n",
    "$$k = \\frac{1}{\\sum_{i=1}^m w(u_a, u_i)}$$\n",
    "- $w(u_a, u_i)$ is similarity between user $u_a$ and a particular user $u_i$. The similarity function could be one of this:\n",
    "    - Pearson Correlation Coefficient:\n",
    "    $$w_p(u_a, u_i) = \\frac{\\sum_j (X_{aj} - n_a)(X_{ij} - n_i)}{\\sqrt{\\sum_j (X_{aj} - n_a)^2 \\sum_j(X_{ij} - n_i)^2}}$$\n",
    "    - Cosine similarity:\n",
    "    $$w_c(u_a, u_i) = \\frac{\\sum_j x_{aj} x_{ij}}{\\sqrt{\\sum_j x_{aj}^2 \\sum_j x_{ij}^2}}$$\n",
    "    \n",
    "Finally:\n",
    "\n",
    "- Predicted rating $\\hat{X}_{aj}$ of object $o_j$ given by user $u_a$ is:\n",
    "$$\\hat{X}_{aj} = \\hat{V}_{aj} + n_a$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the “cold start” problem in collaborative filtering?\n",
    "\n",
    "System has not enough information about the user and there are very few contribution from users, thus system can not start collaborative filtering caused very few recommendation occured at the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Readings and Resources\n",
    "\n",
    "* C. Zhai and S. Massung. Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining, ACM Book Series, Morgan & Claypool Publishers, 2016. Chapters 10 - Section 10.4, Chapters 11\n",
    "* [Recommender system handbook](https://www.cse.iitk.ac.in/users/nsrivast/HCC/Recommender_systems_handbook.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python_3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
